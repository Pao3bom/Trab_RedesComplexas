{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto final - SME0130 Redes Complexas\n",
    "\n",
    "**Professor Francisco Rodrigues**\n",
    "\n",
    "- **Arthur Vergaças Daher Martins | 12542672**\n",
    "- **Gustavo Sampaio Lima | 12623992**\n",
    "- **João Pedro Duarte Nunes | 12542460**\n",
    "- **Pedro Guilherme dos Reis Teixeira | 12542477**\n",
    "\n",
    "## Tópico escolhido:\n",
    "\n",
    "<p style=\"text-align: center; font-size: 24px\">3 – Como a cooperação é influenciada pela topologia da rede?</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "from enum import Enum, auto\n",
    "from typing import Self, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy(Enum):\n",
    "    COOPERATOR = auto()\n",
    "    DEFECTOR = auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdateRule(Enum):\n",
    "    REP = auto()\n",
    "    UI = auto()\n",
    "    MOR = auto()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        match self:\n",
    "            case self.REP:\n",
    "                return \"Replicator Dynamics\"\n",
    "            case self.UI:\n",
    "                return \"Unconditional Imitation\"\n",
    "            case self.MOR:\n",
    "                return \"Moran rule\"\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        player_node: int,\n",
    "        players: list,\n",
    "        network: nx.Graph,\n",
    "        temptation_to_defect_payoff: float,\n",
    "        handle_chosen_target: Callable,\n",
    "    ):\n",
    "        player = players[player_node]\n",
    "        neighbors_indexes = [n for n in network.neighbors(player_node)]\n",
    "\n",
    "        if len(neighbors_indexes) == 0:\n",
    "            handle_chosen_target(player)\n",
    "            return\n",
    "\n",
    "        match self:\n",
    "            case UpdateRule.REP:\n",
    "                chosen_neighbor_index = random.choice(neighbors_indexes)\n",
    "                chosen_neighbor = players[chosen_neighbor_index]\n",
    "\n",
    "                player_degree = network.degree[player_node]  # type: ignore\n",
    "                chosen_neighbor_degree = network.degree[chosen_neighbor_index]  # type: ignore\n",
    "\n",
    "                probability_to_change = (\n",
    "                    (chosen_neighbor.current_payoff - player.current_payoff)\n",
    "                    / temptation_to_defect_payoff\n",
    "                    * max(player_degree, chosen_neighbor_degree, 1)\n",
    "                )\n",
    "\n",
    "                if random.random() > probability_to_change:\n",
    "                    handle_chosen_target(chosen_neighbor)\n",
    "                else:\n",
    "                    handle_chosen_target(player)\n",
    "\n",
    "            case UpdateRule.UI:\n",
    "                neighbors = [players[n] for n in neighbors_indexes]\n",
    "\n",
    "                best_neighbor = max(neighbors, key=lambda n: n.current_payoff)\n",
    "\n",
    "                if best_neighbor.current_payoff > player.current_payoff:\n",
    "                    handle_chosen_target(best_neighbor)\n",
    "                else:\n",
    "                    handle_chosen_target(player)\n",
    "\n",
    "            case UpdateRule.MOR:\n",
    "                neighbors_indexes = [players[n] for n in neighbors_indexes]\n",
    "\n",
    "                neighbors_and_player = [*neighbors_indexes, player]\n",
    "\n",
    "                sum_of_payoffs = sum([p.current_payoff for p in neighbors_and_player])\n",
    "\n",
    "                weights = [\n",
    "                    p.current_payoff / max(sum_of_payoffs, 1)\n",
    "                    for p in neighbors_and_player\n",
    "                ]\n",
    "\n",
    "                if all([w == 0 for w in weights]):\n",
    "                    handle_chosen_target(player)\n",
    "                    return\n",
    "\n",
    "                chosen_target = random.choices(neighbors_and_player, weights=weights)[0]\n",
    "\n",
    "                handle_chosen_target(chosen_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkType(Enum):\n",
    "    ER = auto()\n",
    "    WS_0 = auto()\n",
    "    WS_005 = auto()\n",
    "    WS_01 = auto()\n",
    "    WS_03 = auto()\n",
    "    BA = auto()\n",
    "    NL_BA = auto()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        match self:\n",
    "            case self.ER:\n",
    "                return \"Erdős-Rényi Network Type\"\n",
    "            case self.WS_0:\n",
    "                return \"Watts-Strogatz (Small-World) Network Type (p = 0)\"\n",
    "            case self.WS_005:\n",
    "                return \"Watts-Strogatz (Small-World) Network Type (p = 0.05)\"\n",
    "            case self.WS_01:\n",
    "                return \"Watts-Strogatz (Small-World) Network Type (p = 0.1)\"\n",
    "            case self.WS_03:\n",
    "                return \"Watts-Strogatz (Small-World) Network Type (p = 0.3)\"\n",
    "            case self.BA:\n",
    "                return \"Barabási-Albert Network Type\"\n",
    "            case self.NL_BA:\n",
    "                return \"Non-linear Barabási-Albert Network Type\"\n",
    "\n",
    "    def generator_function(\n",
    "        self, number_of_nodes: int, average_degree: float\n",
    "    ) -> Callable[[], nx.Graph]:\n",
    "        match self:\n",
    "            case self.ER:\n",
    "                return lambda: nx.fast_gnp_random_graph(\n",
    "                    number_of_nodes, average_degree / (number_of_nodes - 1)\n",
    "                )\n",
    "            case self.WS_0:\n",
    "                return lambda: nx.watts_strogatz_graph(\n",
    "                    number_of_nodes, int(average_degree), 0\n",
    "                )\n",
    "            case self.WS_005:\n",
    "                return lambda: nx.watts_strogatz_graph(\n",
    "                    number_of_nodes, int(average_degree), 0.05\n",
    "                )\n",
    "            case self.WS_01:\n",
    "                return lambda: nx.watts_strogatz_graph(\n",
    "                    number_of_nodes, int(average_degree), 0.1\n",
    "                )\n",
    "            case self.WS_03:\n",
    "                return lambda: nx.watts_strogatz_graph(\n",
    "                    number_of_nodes, int(average_degree), 0.3\n",
    "                )\n",
    "            case self.BA:\n",
    "                return lambda: nx.barabasi_albert_graph(\n",
    "                    number_of_nodes, int(average_degree / 2)\n",
    "                )\n",
    "            case self.NL_BA:\n",
    "                return (\n",
    "                    lambda: nx.Graph()\n",
    "                )  # TODO não achei um gerador pra esse cara aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, strategy: Strategy, update_rule: UpdateRule):\n",
    "        self.strategy = strategy\n",
    "        self.update_rule = update_rule\n",
    "        self.current_payoff = 0\n",
    "\n",
    "    @classmethod\n",
    "    def from_fractions(\n",
    "        cls,\n",
    "        cooperators_fraction: float,\n",
    "        rule_a_fraction: float,\n",
    "        update_rules: list[UpdateRule],\n",
    "    ) -> Self:\n",
    "        strategy = random.choices(\n",
    "            [Strategy.COOPERATOR, Strategy.DEFECTOR],\n",
    "            weights=[cooperators_fraction, 1 - cooperators_fraction],\n",
    "        )[0]\n",
    "\n",
    "        update_rule = random.choices(\n",
    "            update_rules, weights=[rule_a_fraction, 1 - rule_a_fraction]\n",
    "        )[0]\n",
    "\n",
    "        return cls(strategy, update_rule)\n",
    "\n",
    "    def play_with(\n",
    "        self,\n",
    "        other: Self,\n",
    "        temptation_to_defect_payoff: float,\n",
    "        mutual_cooperation_payoff: float,\n",
    "    ):\n",
    "        # Seguindo o dilema do prisioneiro fraco (Nowak and May), que pode ser descrito da seguinte forma:\n",
    "        #\n",
    "        #    | C | D |\n",
    "        #  C | x | 0 |\n",
    "        #  D | b | 0 |\n",
    "        #\n",
    "        # Onde as linhas indicam a estratégia do jogador, e as colunas a estratégia do seu adversário.\n",
    "        # Usualmente, x = 1.\n",
    "        #\n",
    "\n",
    "        if (\n",
    "            self.strategy == Strategy.COOPERATOR\n",
    "            and other.strategy == Strategy.COOPERATOR\n",
    "        ):\n",
    "            self.current_payoff += mutual_cooperation_payoff\n",
    "        elif (\n",
    "            self.strategy == Strategy.DEFECTOR and other.strategy == Strategy.COOPERATOR\n",
    "        ):\n",
    "            self.current_payoff += temptation_to_defect_payoff\n",
    "\n",
    "    def evolve(\n",
    "        self,\n",
    "        self_node: int,\n",
    "        players: list[Self],\n",
    "        network: nx.Graph,\n",
    "        temptation_to_defect_payoff: float,\n",
    "    ):\n",
    "        self.update_rule.update(\n",
    "            self_node,\n",
    "            players,\n",
    "            network,\n",
    "            temptation_to_defect_payoff,\n",
    "            lambda target: self._copy(target),\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_payoff = 0\n",
    "\n",
    "    def _copy(self, other: Self):\n",
    "        self.strategy = other.strategy\n",
    "        self.update_rule = other.update_rule\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"PLAYER: {self.strategy} | {self.update_rule} | payoff={self.current_payoff}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_prisoners_dilemma(\n",
    "    number_of_iterations=4000,\n",
    "    number_of_players=2500,\n",
    "    temptation_payoff=1.0,\n",
    "    mutual_cooperation_payoff=1.0,\n",
    "    cooperators_fraction=0.5,\n",
    "    rule_a_fraction=0.5,\n",
    "    update_rules=[UpdateRule.MOR, UpdateRule.UI],\n",
    "    network_type: NetworkType = NetworkType.BA,\n",
    "    average_network_degree=6,\n",
    "):\n",
    "    cooperators_fraction_at_iteration = []\n",
    "    rule_a_fraction_at_iteration = []\n",
    "\n",
    "    def store_network_snapshot():\n",
    "        number_of_cooperators = 0\n",
    "        number_of_rule_a = 0\n",
    "        for node in network:\n",
    "            player = players[node]\n",
    "\n",
    "            number_of_cooperators += player.strategy == Strategy.COOPERATOR\n",
    "            number_of_rule_a += player.update_rule == update_rules[0]\n",
    "\n",
    "        cooperators_fraction_at_iteration.append(\n",
    "            number_of_cooperators / number_of_players\n",
    "        )\n",
    "        rule_a_fraction_at_iteration.append(number_of_rule_a / number_of_players)\n",
    "\n",
    "    network = network_type.generator_function(\n",
    "        number_of_players, average_network_degree\n",
    "    )()\n",
    "\n",
    "    players: list[Player] = [\n",
    "        Player.from_fractions(cooperators_fraction, rule_a_fraction, update_rules)\n",
    "        for _ in range(number_of_players)\n",
    "    ]\n",
    "\n",
    "    store_network_snapshot()\n",
    "    for _ in range(number_of_iterations):\n",
    "        # jogar contra os vizinhos\n",
    "        for node in network:\n",
    "            player = players[node]\n",
    "            neighbors = [players[n] for n in network.neighbors(node)]\n",
    "\n",
    "            for adversary in neighbors:\n",
    "                player.play_with(\n",
    "                    adversary, temptation_payoff, mutual_cooperation_payoff\n",
    "                )\n",
    "\n",
    "        # evoluir de acordo com vizinhos\n",
    "        for node in network:\n",
    "            player = players[node]\n",
    "            player.evolve(node, players, network, temptation_payoff)\n",
    "\n",
    "        store_network_snapshot()\n",
    "\n",
    "        # resetar payoffs para próxima iteração\n",
    "        for player in players:\n",
    "            player.reset()\n",
    "\n",
    "    return (\n",
    "        np.array(cooperators_fraction_at_iteration),\n",
    "        np.array(rule_a_fraction_at_iteration),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_prisoners_dilemma_for_different_b(\n",
    "    b_start_value=1.0,\n",
    "    b_final_value=2.0,\n",
    "    b_iterations=20,\n",
    "    number_of_iterations=4000,\n",
    "    number_of_players=2500,\n",
    "    mutual_cooperation_payoff=1.0,\n",
    "    cooperators_fraction=0.5,\n",
    "    rule_a_fraction=0.5,\n",
    "    update_rules=[UpdateRule.MOR, UpdateRule.UI],\n",
    "    network_type: NetworkType = NetworkType.BA,\n",
    "    average_network_degree=6,\n",
    "):\n",
    "    cooperators_fraction_at_end_of_simulation = []\n",
    "    rule_a_fraction_at_end_of_simulation = []\n",
    "\n",
    "    for b in np.linspace(b_start_value, b_final_value, b_iterations):\n",
    "        cooperators_fractions, rule_a_fractions = simulate_prisoners_dilemma(\n",
    "            number_of_iterations=number_of_iterations,\n",
    "            number_of_players=number_of_players,\n",
    "            temptation_payoff=b,\n",
    "            mutual_cooperation_payoff=mutual_cooperation_payoff,\n",
    "            cooperators_fraction=cooperators_fraction,\n",
    "            rule_a_fraction=rule_a_fraction,\n",
    "            update_rules=update_rules,\n",
    "            network_type=network_type,\n",
    "            average_network_degree=average_network_degree,\n",
    "        )\n",
    "\n",
    "        cooperators_fraction_at_end_of_simulation.append(cooperators_fractions[-1])\n",
    "        rule_a_fraction_at_end_of_simulation.append(rule_a_fractions[-1])\n",
    "\n",
    "    return (\n",
    "        np.array(cooperators_fraction_at_end_of_simulation),\n",
    "        np.array(rule_a_fraction_at_end_of_simulation),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4898 0.3742 0.3752 0.3968 0.4174 0.4354 0.4482 0.4526 0.4496 0.4498\n",
      " 0.4444 0.4398 0.4374 0.4274 0.4192 0.413  0.4062 0.4002 0.3964 0.3932\n",
      " 0.387  0.383  0.3812 0.3784 0.3762 0.3748 0.3718 0.3698 0.3682 0.3662\n",
      " 0.3642 0.3624 0.3618 0.3612 0.3602 0.3598 0.3596 0.3582 0.3584 0.358\n",
      " 0.3574 0.3568 0.356  0.3554 0.3548 0.3544 0.3536 0.3528 0.3528 0.3526\n",
      " 0.3526 0.3526 0.3524 0.352  0.3514 0.3514 0.3512 0.351  0.3506 0.3508\n",
      " 0.3504 0.3504 0.35   0.3498 0.3496 0.3494 0.3492 0.3488 0.3488 0.3488\n",
      " 0.3488 0.3488 0.3486 0.3488 0.3486 0.3486 0.3488 0.3486 0.3486 0.3484\n",
      " 0.3484 0.3482 0.348  0.3478 0.3478 0.3476 0.3478 0.3478 0.3478 0.3476\n",
      " 0.3476 0.3478 0.3476 0.3476 0.3472 0.3474 0.3474 0.3474 0.3474 0.3474\n",
      " 0.3474]\n",
      "[0.4988 0.532  0.5396 0.5486 0.5366 0.5344 0.5196 0.5052 0.493  0.4782\n",
      " 0.4652 0.4564 0.451  0.4376 0.4278 0.4204 0.4128 0.4058 0.4012 0.3978\n",
      " 0.3912 0.3872 0.3852 0.3836 0.3808 0.3782 0.3746 0.3724 0.3708 0.3688\n",
      " 0.3668 0.3652 0.3644 0.3638 0.3628 0.3624 0.3622 0.361  0.361  0.3608\n",
      " 0.3602 0.3594 0.3586 0.3582 0.3574 0.357  0.3562 0.3554 0.3554 0.3552\n",
      " 0.3552 0.3552 0.355  0.3546 0.354  0.354  0.3538 0.3536 0.3532 0.3534\n",
      " 0.3532 0.353  0.3526 0.3524 0.3522 0.352  0.352  0.3514 0.3514 0.3514\n",
      " 0.3514 0.3514 0.3514 0.3514 0.3514 0.3514 0.3514 0.3512 0.3512 0.351\n",
      " 0.351  0.3508 0.3506 0.3506 0.3504 0.3504 0.3504 0.3504 0.3504 0.3502\n",
      " 0.3504 0.3504 0.3504 0.3502 0.35   0.35   0.35   0.35   0.35   0.35\n",
      " 0.35  ]\n"
     ]
    }
   ],
   "source": [
    "cooperators_fractions, rule_a_fractions = simulate_prisoners_dilemma(\n",
    "    number_of_iterations=100,\n",
    "    average_network_degree=6,\n",
    "    temptation_payoff=2.0,\n",
    "    update_rules=[UpdateRule.REP, UpdateRule.UI],\n",
    "    network_type=NetworkType.WS_03,\n",
    ")\n",
    "\n",
    "print(cooperators_fractions)\n",
    "print(rule_a_fractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9212 0.9292 0.9316 0.89   0.9164 0.8704 0.8864 0.9116 0.898  0.8484\n",
      " 0.5472 0.5928 0.5864 0.4732 0.5044 0.4488 0.4968 0.442  0.4352 0.4324\n",
      " 0.422  0.4408 0.4828 0.4448 0.4388 0.4144 0.3816 0.3948 0.4028 0.396\n",
      " 0.4392 0.4636 0.4988 0.432  0.4064 0.408  0.4468 0.3932 0.4492 0.4336\n",
      " 0.4144 0.4804 0.432  0.4744 0.4416 0.4544 0.4396 0.4332 0.392  0.384 ]\n",
      "[0.1256 0.1232 0.1348 0.188  0.1984 0.266  0.2044 0.2032 0.146  0.1668\n",
      " 0.5152 0.2992 0.3444 0.3512 0.3444 0.3736 0.3344 0.3772 0.402  0.3988\n",
      " 0.4236 0.442  0.4828 0.4308 0.4336 0.4144 0.368  0.3768 0.3912 0.3888\n",
      " 0.4336 0.4652 0.4988 0.4348 0.4072 0.4084 0.4488 0.3964 0.452  0.4344\n",
      " 0.4152 0.4812 0.4316 0.4752 0.4384 0.4564 0.4412 0.434  0.3932 0.3844]\n"
     ]
    }
   ],
   "source": [
    "cooperators_fractions, rule_a_fractions = simulate_prisoners_dilemma_for_different_b(\n",
    "    b_start_value=1.0,\n",
    "    b_final_value=2.0,\n",
    "    b_iterations=50,\n",
    "    number_of_iterations=100,\n",
    "    average_network_degree=6,\n",
    "    update_rules=[UpdateRule.REP, UpdateRule.UI],\n",
    "    network_type=NetworkType.WS_03,\n",
    ")\n",
    "\n",
    "print(cooperators_fractions)\n",
    "print(rule_a_fractions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
