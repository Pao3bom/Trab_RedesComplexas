{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto final - SME0130 Redes Complexas\n",
    "\n",
    "**Professor Francisco Rodrigues**\n",
    "\n",
    "- **Arthur Vergaças Daher Martins | 12542672**\n",
    "- **Gustavo Sampaio Lima | 12623992**\n",
    "- **João Pedro Duarte Nunes | 12542460**\n",
    "- **Pedro Guilherme dos Reis Teixeira | 12542477**\n",
    "\n",
    "## Tópico escolhido:\n",
    "\n",
    "<p style=\"text-align: center; font-size: 24px\">3 – Como a cooperação é influenciada pela topologia da rede?</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from enum import Enum, auto\n",
    "from typing import Self, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategy(Enum):\n",
    "    COOPERATOR = auto()\n",
    "    DEFECTOR = auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdateRule(Enum):\n",
    "    REP = auto()\n",
    "    UI = auto()\n",
    "    MOR = auto()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        match self:\n",
    "            case self.REP:\n",
    "                return \"Replicator Dynamics\"\n",
    "            case self.UI:\n",
    "                return \"Unconditional Imitation\"\n",
    "            case self.MOR:\n",
    "                return \"Moran rule\"\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        player_node: int,\n",
    "        players: list,\n",
    "        network: nx.Graph,\n",
    "        temptation_to_defect_payoff: float,\n",
    "        handle_chosen_target: Callable,\n",
    "    ):\n",
    "        player = players[player_node]\n",
    "        neighbors_indexes = [n for n in network.neighbors(player_node)]\n",
    "\n",
    "        if len(neighbors_indexes) == 0:\n",
    "            handle_chosen_target(player)\n",
    "            return\n",
    "\n",
    "        match self:\n",
    "            case UpdateRule.REP:\n",
    "                chosen_neighbor_index = random.choice(neighbors_indexes)\n",
    "                chosen_neighbor = players[chosen_neighbor_index]\n",
    "\n",
    "                player_degree = network.degree[player_node]  # type: ignore\n",
    "                chosen_neighbor_degree = network.degree[chosen_neighbor_index]  # type: ignore\n",
    "\n",
    "                probability_to_change = (\n",
    "                    (chosen_neighbor.current_payoff - player.current_payoff)\n",
    "                    / temptation_to_defect_payoff\n",
    "                    * max(player_degree, chosen_neighbor_degree, 1)\n",
    "                )\n",
    "\n",
    "                if random.random() > probability_to_change:\n",
    "                    handle_chosen_target(chosen_neighbor)\n",
    "                else:\n",
    "                    handle_chosen_target(player)\n",
    "\n",
    "            case UpdateRule.UI:\n",
    "                neighbors = [players[n] for n in neighbors_indexes]\n",
    "\n",
    "                best_neighbor = max(neighbors, key=lambda n: n.current_payoff)\n",
    "\n",
    "                if best_neighbor.current_payoff > player.current_payoff:\n",
    "                    handle_chosen_target(best_neighbor)\n",
    "                else:\n",
    "                    handle_chosen_target(player)\n",
    "\n",
    "            case UpdateRule.MOR:\n",
    "                neighbors_indexes = [players[n] for n in neighbors_indexes]\n",
    "\n",
    "                neighbors_and_player = [*neighbors_indexes, player]\n",
    "\n",
    "                sum_of_payoffs = sum([p.current_payoff for p in neighbors_and_player])\n",
    "\n",
    "                weights = [\n",
    "                    p.current_payoff / max(sum_of_payoffs, 1)\n",
    "                    for p in neighbors_and_player\n",
    "                ]\n",
    "\n",
    "                if all([w == 0 for w in weights]):\n",
    "                    handle_chosen_target(player)\n",
    "                    return\n",
    "\n",
    "                chosen_target = random.choices(neighbors_and_player, weights=weights)[0]\n",
    "\n",
    "                handle_chosen_target(chosen_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_subset(seq: list, m: int, probabilities: None|list = None):\n",
    "    \"\"\"\n",
    "    Return m elements of a sequence, probabilities for each element can de defined, if not uniform distribution is assumed.\n",
    "\n",
    "    Differently from the usual np.random.choice de use of a set garantees that no repeated elements will be returned.\n",
    "    \"\"\"\n",
    "\n",
    "    targets = set()\n",
    "    while len(targets) < m:\n",
    "        x = np.random.choice(seq, p=probabilities)\n",
    "        targets.add(x)\n",
    "    return targets\n",
    "\n",
    "def normalize_prob(probabilities: list):\n",
    "    \"\"\"\n",
    "    Given a list of probabilities they are normalized so that their sum is equal to 1\n",
    "    \"\"\"\n",
    "    full_sum = sum(probabilities)\n",
    "    normalized_probabilities = list(map(lambda x: x/full_sum, probabilities))\n",
    "    return normalized_probabilities\n",
    "\n",
    "\n",
    "def non_linear_barabasi_albert_graph(n, m, power=1, initial_graph=None):\n",
    "    \"\"\"\n",
    "    Generates a random non-linear Barabasi Albert Graph. \n",
    "    \n",
    "    If power > 1 it generates a Superlinear Barabasi Albert Graph\n",
    "    If power < 1 it generates a Sublinear Barabasi Albert Graph\n",
    "    If power = 1 it generates a Linear Barabasi Albert Graph\n",
    "\n",
    "    If no power is given it generates a Linear Barabasi Albert Graph\n",
    "    \"\"\"\n",
    "    \n",
    "    if m < 1 or m >= n: raise nx.NetworkXError(f\"Barabási–Albert network must have m >= 1 and m < n, m = {m}, n = {n}\")\n",
    "    if power <= 0: raise nx.NetworkXError(f\"Power must not be zero or negative, power = {power}\")\n",
    "\n",
    "    if initial_graph is None:\n",
    "        # Default initial graph : star graph on (m + 1) nodes\n",
    "        G = nx.star_graph(m)\n",
    "    else:\n",
    "        if len(initial_graph) < m or len(initial_graph) > n:\n",
    "            raise nx.NetworkXError(\n",
    "                f\"Barabási–Albert initial graph needs between m={m} and n={n} nodes\"\n",
    "            )\n",
    "        G = initial_graph.copy()\n",
    "\n",
    "    # Lists existing nodes, their degrees and their preference in the attachment according to the choosen power\n",
    "    nodes = list(G.nodes)\n",
    "    degrees = []\n",
    "    probabilities = []\n",
    "    for _, degree in sorted(G.degree(), key=lambda pair: pair[0]):\n",
    "        degrees.append(degree)\n",
    "        probabilities.append(pow(degree, power))\n",
    "    \n",
    "    # Start adding the other n - m0 nodes.\n",
    "    source = len(G)\n",
    "    while source < n:\n",
    "        \n",
    "        # Chooses m unique nodes from the existing ones following the preferential attachment\n",
    "        targets = random_subset(nodes, m, normalize_prob(probabilities))\n",
    "        # Add edges to m nodes from the source.\n",
    "        G.add_edges_from(zip([source] * m, targets))\n",
    "        \n",
    "        for target in targets:\n",
    "            degrees[target] += 1  # Increases the degree of each node which received a new connection\n",
    "            probabilities[target] = pow(degrees[target], power)  # Gets the new preference for the node according to their new degree\n",
    "        \n",
    "        nodes.append(source)  # Adds source to the list of nodes\n",
    "        degrees.append(m)  # Adds the degree of source to the list of degrees\n",
    "        probabilities.append(pow(m, power))  # Adds the preference of source to the list of probabilites\n",
    "\n",
    "        source += 1\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkType(Enum):\n",
    "    ER = auto()\n",
    "    WS_0 = auto()\n",
    "    WS_005 = auto()\n",
    "    WS_01 = auto()\n",
    "    WS_03 = auto()\n",
    "    BA = auto()\n",
    "    SUB_BA = auto()\n",
    "    SUPER_BA = auto()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        match self:\n",
    "            case self.ER:\n",
    "                return \"Erdős-Rényi Network Type\"\n",
    "            case self.WS_0:\n",
    "                return \"Watts-Strogatz (Small-World) Network Type (p = 0)\"\n",
    "            case self.WS_005:\n",
    "                return \"Watts-Strogatz (Small-World) Network Type (p = 0.05)\"\n",
    "            case self.WS_01:\n",
    "                return \"Watts-Strogatz (Small-World) Network Type (p = 0.1)\"\n",
    "            case self.WS_03:\n",
    "                return \"Watts-Strogatz (Small-World) Network Type (p = 0.3)\"\n",
    "            case self.BA:\n",
    "                return \"Barabási-Albert Network Type\"\n",
    "            case self.SUB_BA:\n",
    "                return \"Sublinear Barabási-Albert Network Type\"\n",
    "            case self.SUPER_BA:\n",
    "                return \"Superlinear Barabási-Albert Network Type\"\n",
    "\n",
    "    def generator_function(\n",
    "        self, number_of_nodes: int, average_degree: float\n",
    "    ) -> Callable[[], nx.Graph]:\n",
    "        match self:\n",
    "            case self.ER:\n",
    "                return lambda: nx.fast_gnp_random_graph(\n",
    "                    number_of_nodes, average_degree / (number_of_nodes - 1)\n",
    "                )\n",
    "            case self.WS_0:\n",
    "                return lambda: nx.watts_strogatz_graph(\n",
    "                    number_of_nodes, int(average_degree), 0\n",
    "                )\n",
    "            case self.WS_005:\n",
    "                return lambda: nx.watts_strogatz_graph(\n",
    "                    number_of_nodes, int(average_degree), 0.05\n",
    "                )\n",
    "            case self.WS_01:\n",
    "                return lambda: nx.watts_strogatz_graph(\n",
    "                    number_of_nodes, int(average_degree), 0.1\n",
    "                )\n",
    "            case self.WS_03:\n",
    "                return lambda: nx.watts_strogatz_graph(\n",
    "                    number_of_nodes, int(average_degree), 0.3\n",
    "                )\n",
    "            case self.BA:\n",
    "                return lambda: nx.barabasi_albert_graph(\n",
    "                    number_of_nodes, int(average_degree / 2)\n",
    "                )\n",
    "            case self.SUB_BA:\n",
    "                return (\n",
    "                    lambda: non_linear_barabasi_albert_graph\n",
    "                    (number_of_nodes, int(average_degree / 2), power=0.5)\n",
    "                )  \n",
    "            case self.SUPER_BA:\n",
    "                return (\n",
    "                    lambda: non_linear_barabasi_albert_graph\n",
    "                    (number_of_nodes, int(average_degree / 2), power=2)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, strategy: Strategy, update_rule: UpdateRule):\n",
    "        self.strategy = strategy\n",
    "        self.update_rule = update_rule\n",
    "        self.current_payoff = 0\n",
    "\n",
    "    @classmethod\n",
    "    def from_fractions(\n",
    "        cls,\n",
    "        cooperators_fraction: float,\n",
    "        rule_a_fraction: float,\n",
    "        update_rules: list[UpdateRule],\n",
    "    ) -> Self:\n",
    "        strategy = random.choices(\n",
    "            [Strategy.COOPERATOR, Strategy.DEFECTOR],\n",
    "            weights=[cooperators_fraction, 1 - cooperators_fraction],\n",
    "        )[0]\n",
    "\n",
    "        update_rule = random.choices(\n",
    "            update_rules, weights=[rule_a_fraction, 1 - rule_a_fraction]\n",
    "        )[0]\n",
    "\n",
    "        return cls(strategy, update_rule)\n",
    "\n",
    "    def play_with(\n",
    "        self,\n",
    "        other: Self,\n",
    "        temptation_to_defect_payoff: float,\n",
    "        mutual_cooperation_payoff: float,\n",
    "    ):\n",
    "        # Seguindo o dilema do prisioneiro fraco (Nowak and May), que pode ser descrito da seguinte forma:\n",
    "        #\n",
    "        #    | C | D |\n",
    "        #  C | x | 0 |\n",
    "        #  D | b | 0 |\n",
    "        #\n",
    "        # Onde as linhas indicam a estratégia do jogador, e as colunas a estratégia do seu adversário.\n",
    "        # Usualmente, x = 1.\n",
    "        #\n",
    "\n",
    "        if (\n",
    "            self.strategy == Strategy.COOPERATOR\n",
    "            and other.strategy == Strategy.COOPERATOR\n",
    "        ):\n",
    "            self.current_payoff += mutual_cooperation_payoff\n",
    "        elif (\n",
    "            self.strategy == Strategy.DEFECTOR and other.strategy == Strategy.COOPERATOR\n",
    "        ):\n",
    "            self.current_payoff += temptation_to_defect_payoff\n",
    "\n",
    "    def evolve(\n",
    "        self,\n",
    "        self_node: int,\n",
    "        players: list[Self],\n",
    "        network: nx.Graph,\n",
    "        temptation_to_defect_payoff: float,\n",
    "    ):\n",
    "        self.update_rule.update(\n",
    "            self_node,\n",
    "            players,\n",
    "            network,\n",
    "            temptation_to_defect_payoff,\n",
    "            lambda target: self._copy(target),\n",
    "        )\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_payoff = 0\n",
    "\n",
    "    def _copy(self, other: Self):\n",
    "        self.strategy = other.strategy\n",
    "        self.update_rule = other.update_rule\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"PLAYER: {self.strategy} | {self.update_rule} | payoff={self.current_payoff}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_prisoners_dilemma(\n",
    "    number_of_iterations=4000,\n",
    "    number_of_players=2500,\n",
    "    temptation_payoff=1.0,\n",
    "    mutual_cooperation_payoff=1.0,\n",
    "    cooperators_fraction=0.5,\n",
    "    rule_a_fraction=0.5,\n",
    "    update_rules=[UpdateRule.MOR, UpdateRule.UI],\n",
    "    network_type: NetworkType = NetworkType.BA,\n",
    "    average_network_degree=6,\n",
    "):\n",
    "    cooperators_fraction_at_iteration = []\n",
    "    rule_a_fraction_at_iteration = []\n",
    "\n",
    "    def store_network_snapshot():\n",
    "        number_of_cooperators = 0\n",
    "        number_of_rule_a = 0\n",
    "        for node in network:\n",
    "            player = players[node]\n",
    "\n",
    "            number_of_cooperators += player.strategy == Strategy.COOPERATOR\n",
    "            number_of_rule_a += player.update_rule == update_rules[0]\n",
    "\n",
    "        cooperators_fraction_at_iteration.append(\n",
    "            number_of_cooperators / number_of_players\n",
    "        )\n",
    "        rule_a_fraction_at_iteration.append(number_of_rule_a / number_of_players)\n",
    "\n",
    "    network = network_type.generator_function(\n",
    "        number_of_players, average_network_degree\n",
    "    )()\n",
    "\n",
    "    players: list[Player] = [\n",
    "        Player.from_fractions(cooperators_fraction, rule_a_fraction, update_rules)\n",
    "        for _ in range(number_of_players)\n",
    "    ]\n",
    "\n",
    "    store_network_snapshot()\n",
    "    for _ in range(number_of_iterations):\n",
    "        # jogar contra os vizinhos\n",
    "        for node in network:\n",
    "            player = players[node]\n",
    "            neighbors = [players[n] for n in network.neighbors(node)]\n",
    "\n",
    "            for adversary in neighbors:\n",
    "                player.play_with(\n",
    "                    adversary, temptation_payoff, mutual_cooperation_payoff\n",
    "                )\n",
    "\n",
    "        # evoluir de acordo com vizinhos\n",
    "        players_snapshot = [\n",
    "            deepcopy(p) for p in players\n",
    "        ]  # copiar estado dos jogadores para que a evolução ocorra em paralelo\n",
    "\n",
    "        for node in network:\n",
    "            player = players[node]\n",
    "            player.evolve(node, players_snapshot, network, temptation_payoff)\n",
    "\n",
    "        store_network_snapshot()\n",
    "\n",
    "        # resetar payoffs para próxima iteração\n",
    "        for player in players:\n",
    "            player.reset()\n",
    "\n",
    "    return (\n",
    "        np.array(cooperators_fraction_at_iteration),\n",
    "        np.array(rule_a_fraction_at_iteration),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_prisoners_dilemma_for_different_b(\n",
    "    b_start_value=1.0,\n",
    "    b_final_value=2.0,\n",
    "    b_iterations=20,\n",
    "    number_of_iterations=4000,\n",
    "    number_of_players=2500,\n",
    "    mutual_cooperation_payoff=1.0,\n",
    "    cooperators_fraction=0.5,\n",
    "    rule_a_fraction=0.5,\n",
    "    update_rules=[UpdateRule.MOR, UpdateRule.UI],\n",
    "    network_type: NetworkType = NetworkType.BA,\n",
    "    average_network_degree=6,\n",
    "):\n",
    "    cooperators_fraction_at_end_of_simulation = []\n",
    "    rule_a_fraction_at_end_of_simulation = []\n",
    "\n",
    "    for b in np.linspace(b_start_value, b_final_value, b_iterations):\n",
    "        cooperators_fractions, rule_a_fractions = simulate_prisoners_dilemma(\n",
    "            number_of_iterations=number_of_iterations,\n",
    "            number_of_players=number_of_players,\n",
    "            temptation_payoff=b,\n",
    "            mutual_cooperation_payoff=mutual_cooperation_payoff,\n",
    "            cooperators_fraction=cooperators_fraction,\n",
    "            rule_a_fraction=rule_a_fraction,\n",
    "            update_rules=update_rules,\n",
    "            network_type=network_type,\n",
    "            average_network_degree=average_network_degree,\n",
    "        )\n",
    "\n",
    "        cooperators_fraction_at_end_of_simulation.append(cooperators_fractions[-1])\n",
    "        rule_a_fraction_at_end_of_simulation.append(rule_a_fractions[-1])\n",
    "\n",
    "    return (\n",
    "        np.array(cooperators_fraction_at_end_of_simulation),\n",
    "        np.array(rule_a_fraction_at_end_of_simulation),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5088 0.4388 0.4156 0.4192 0.4412 0.4796 0.5112 0.5212 0.5432 0.57\n",
      " 0.584  0.5936 0.6052 0.6236 0.6364 0.6468 0.6656 0.6692 0.668  0.6648\n",
      " 0.664  0.6612 0.6568 0.6544 0.6532 0.6496 0.6436 0.6356 0.6292 0.6264\n",
      " 0.6236 0.6228 0.6168 0.6128 0.6064 0.6004 0.6008 0.596  0.594  0.5884\n",
      " 0.5868 0.584  0.5796 0.5764 0.5744 0.5736 0.5716 0.5696 0.5668 0.5644\n",
      " 0.5624 0.5608 0.5572 0.556  0.5536 0.5528 0.55   0.5452 0.5448 0.544\n",
      " 0.5412 0.5384 0.5384 0.5364 0.5364 0.5364 0.5336 0.532  0.5288 0.5304\n",
      " 0.5296 0.53   0.5276 0.5268 0.5268 0.5272 0.5276 0.5272 0.528  0.526\n",
      " 0.526  0.5256 0.5244 0.5252 0.522  0.5232 0.5232 0.522  0.522  0.5204\n",
      " 0.5208 0.5196 0.52   0.5176 0.518  0.518  0.5184 0.5148 0.516  0.5148\n",
      " 0.514 ]\n",
      "[0.4948 0.5704 0.6144 0.6528 0.688  0.708  0.7128 0.7272 0.7264 0.7256\n",
      " 0.7312 0.7316 0.7336 0.7372 0.7404 0.7432 0.738  0.7348 0.7284 0.7208\n",
      " 0.7152 0.7104 0.7032 0.7032 0.6988 0.692  0.6808 0.6708 0.6644 0.6624\n",
      " 0.6584 0.654  0.6468 0.6412 0.6356 0.6304 0.6296 0.6232 0.6196 0.6156\n",
      " 0.6124 0.6084 0.6036 0.6    0.5976 0.5984 0.5928 0.5908 0.588  0.5848\n",
      " 0.5832 0.5804 0.5768 0.576  0.5724 0.5708 0.5676 0.564  0.5632 0.562\n",
      " 0.5588 0.5576 0.5564 0.554  0.5548 0.5516 0.5488 0.548  0.5456 0.5464\n",
      " 0.5456 0.5452 0.544  0.544  0.5436 0.5436 0.5428 0.5428 0.542  0.54\n",
      " 0.5392 0.54   0.5396 0.5392 0.5368 0.5368 0.536  0.5356 0.5352 0.534\n",
      " 0.5336 0.532  0.5308 0.53   0.5308 0.5308 0.5304 0.5288 0.5284 0.528\n",
      " 0.5272]\n"
     ]
    }
   ],
   "source": [
    "cooperators_fractions, rule_a_fractions = simulate_prisoners_dilemma(\n",
    "    number_of_iterations=100,\n",
    "    average_network_degree=6,\n",
    "    temptation_payoff=1.5,\n",
    "    update_rules=[UpdateRule.REP, UpdateRule.UI],\n",
    "    network_type=NetworkType.ER,\n",
    ")\n",
    "\n",
    "print(cooperators_fractions)\n",
    "print(rule_a_fractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9212 0.9292 0.9316 0.89   0.9164 0.8704 0.8864 0.9116 0.898  0.8484\n",
      " 0.5472 0.5928 0.5864 0.4732 0.5044 0.4488 0.4968 0.442  0.4352 0.4324\n",
      " 0.422  0.4408 0.4828 0.4448 0.4388 0.4144 0.3816 0.3948 0.4028 0.396\n",
      " 0.4392 0.4636 0.4988 0.432  0.4064 0.408  0.4468 0.3932 0.4492 0.4336\n",
      " 0.4144 0.4804 0.432  0.4744 0.4416 0.4544 0.4396 0.4332 0.392  0.384 ]\n",
      "[0.1256 0.1232 0.1348 0.188  0.1984 0.266  0.2044 0.2032 0.146  0.1668\n",
      " 0.5152 0.2992 0.3444 0.3512 0.3444 0.3736 0.3344 0.3772 0.402  0.3988\n",
      " 0.4236 0.442  0.4828 0.4308 0.4336 0.4144 0.368  0.3768 0.3912 0.3888\n",
      " 0.4336 0.4652 0.4988 0.4348 0.4072 0.4084 0.4488 0.3964 0.452  0.4344\n",
      " 0.4152 0.4812 0.4316 0.4752 0.4384 0.4564 0.4412 0.434  0.3932 0.3844]\n"
     ]
    }
   ],
   "source": [
    "cooperators_fractions, rule_a_fractions = simulate_prisoners_dilemma_for_different_b(\n",
    "    b_start_value=1.0,\n",
    "    b_final_value=2.0,\n",
    "    b_iterations=50,\n",
    "    number_of_iterations=100,\n",
    "    average_network_degree=6,\n",
    "    update_rules=[UpdateRule.REP, UpdateRule.UI],\n",
    "    network_type=NetworkType.WS_03,\n",
    ")\n",
    "\n",
    "print(cooperators_fractions)\n",
    "print(rule_a_fractions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
